<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.19 (466516)"/><meta name="keywords" content="prompt, review"/><meta name="author" content="songdj"/><meta name="created" content="2021-11-27 13:45:20 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="updated" content="2022-04-15 14:34:29 +0000"/><title>提示学习 Prompt Learning</title></head><body><div>本文介绍了Prompting Methods在NLP领域的应用。</div><div>prompt有点像是知识引导的方式，通过引入额外的知识，让LM进行对应的推理。</div><div><br/></div><div>为什么有效？</div><ol><li><div>下游任务的数据分布向预训练任务的数据分布靠拢</div></li><li><div>prompt作为一种指导，在attention机制下引导模型生成需要的token。如情感分类任务需要模型特别关注情感相关的观点词。因此在一些只关注于input自身的任务上，如SQUAD抽取式问答，不需要引入额外的指导，仅通过文章和问题就能获得答案，效果不会有情感分类任务那样显著。【2】</div></li></ol><div><br/></div><div>概念区别：</div><ol><li><div>fine-tuning：更新整个模型的参数，为每一个任务产生一个模型副本。时间成本和空间成本较高，对于较大的模型不友好。</div></li><li><div>prompting：为每一个下游任务设计一个prompt，只保存一个模型副本。节省了空间资源，但是设计prompt需要大量专家知识，且无法找到一个最优的模板。在部分任务上的性能没有超过fine-tuning。</div></li><li><div>prompt-tuning：最早由【3】【4】提出，将一段可训练的连续的词嵌入拼接到输入中。在模型较小时或较难任务（相比于GLUE数据集的多类别分类任务）上的性能差于fine-tuning。</div></li></ol><div><br/></div><div /><div><br/></div><div><br/></div><hr/><div><br/></div><h1>1. 目录</h1><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/D855D2C3-3C5A-4F25-96C7-3ADBA74A1BB2.png" height="1268" width="1082"/><h1>2. 概述</h1><h2>学习范式</h2><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/C17BE450-AC70-4F47-906D-781A87D32DE0.png" height="814" width="1072"/><h2>prompt相关标记 </h2><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/A6A0B4C7-E368-4015-92E6-D7352FEE9C13.png" height="508" width="1084"/><h2>针对不同任务的prompt示例</h2><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/224979E4-46DC-46B0-AC44-523B99E8DA2F.png" height="814" width="1054"/><h2>prompting method分类</h2><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/1AD6016C-1BB1-4821-B5E7-96C79095D277.png" height="1692" width="1162"/><h1>3. 预训练模型</h1><h2>3.1 Training Objectives</h2><div>Standard Language Model (SLM)：GPT</div><p style="text-align:start;">Corrupted Text Reconstruction (CTR)</p><p style="text-align:start;">Full Text Reconstruction (FTR)：完全重建 BART</p><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/B11FD702-2A1C-4EE1-8107-3E92954661B6.png" height="737" width="745"/><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/6692B083-4E12-4B79-A613-B7DB38371E2D.png" height="218" width="746"/><h2>3.2 Noising Functions</h2><div>仅针对于reconstruction的训练目标</div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/3E8A13A2-1884-40D4-8DAD-004C9618B3D6.png" height="278" width="743"/><h2>3.3 Directionality of Representations</h2><p>Left-to-Right</p><p>Bi-directional</p><p>Mix</p><p><br/></p><div>实际操作时，可以使用不同的Attention Masking策略：</div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/F1176A73-9011-4E42-AB98-414135D8B332.png" height="255" width="752"/><h2>3.4 Typical Pre-training Methods</h2><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/9B1EB00B-1BE1-4DFC-B08D-17D552E4672B.png" height="216" width="731"/><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/1FB2F0AB-27CF-415E-9EC5-42A277ED502B.png" height="213" width="751"/><h1>4. Prompt Engineering</h1><div>人类工程师或算法为模型所要执行的每项任务寻找最佳模板。必须首先考虑提示的形状，然后决定是采取手动还是自动的方式来创建所需的prompt。</div><h2>4.1 Prompt Shape</h2><h3>cloze prompts</h3><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>Language Models as Knowledge Bases?</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/23C3352C-7CC6-4D43-A28C-6ED21EA78C91.png" height="766" width="1008"/><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>Template-Based Named Entity Recognition Using BART</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/1CEFDB74-E230-4B87-9B24-258EAFB293CC.png" height="578" width="1522"/><h3>prefix prompts</h3><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/e4022f45-2476-4933-bbc6-d30d98567f51/e4022f45-2476-4933-bbc6-d30d98567f51/" rev="en_rl_none">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></div><div>GPT-2/BART</div><div>每一层prefix</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/C2CA2E66-F11C-41F5-90D1-ABD28C85874D.png" height="774" width="1016"/><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>The Power of Scale for Parameter-Efficient Prompt Tuning</div><div>T5</div><div>第一层prefix</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/0B1B2F54-F24E-4A25-A579-E60E9F6FAED3.png" height="564" width="1100"/><h2>4.2 Manual Template Engineering</h2><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>Language Models as Knowledge Bases?</div><div>LAMA数据集，提供人工构造的cloze template探测模型中的知识；</div></div><h2>4.3 Automated Template Learning</h2><div>人工构造耗时，需要专家知识；sub-optimal；</div><h3>4.3.1 Discrete/Hard Prompts——text string</h3><div>D1: Prompt Mining</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/88f01871-89f5-4633-be16-f2d215d3f982/88f01871-89f5-4633-be16-f2d215d3f982/" rev="en_rl_none">LPAQA: How Can We Know What Language Models Know?</a></div><div>在大型文本语料库（如维基百科）中搜索包含x和y的字符串，并找到输入和输出之间的中间词或依赖路径。</div></div><div>D2: Prompt Paraphrasing</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>利用现有的seed prompt（如人工构建的或挖掘的），并将其转述为一组其他的候选prompt，然后选择在目标任务上达到最高训练精度的prompt。</div><div>转述方法有：回译、替换为词库中的短语、neural prompt rewriter</div><div><a href="evernote:///view/24256724/s35/88f01871-89f5-4633-be16-f2d215d3f982/88f01871-89f5-4633-be16-f2d215d3f982/" rev="en_rl_none">LPAQA: How Can We Know What Language Models Know?</a> back-translation</div></div><div>D3: Gradient-based Search</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/bde186a5-8fe5-4c23-9d8f-92a43e512106/bde186a5-8fe5-4c23-9d8f-92a43e512106/" rev="en_rl_none">AUTOPROMPT: Eliciting Knowledge from Language Models with Automatically Generated Prompts</a></div><div>在实际token上进行梯度的搜索，寻找能够触发LM以产生所需预测目标的短序列。</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/C0E15EFA-7521-4220-A58B-EB5E557C7C45.png" height="619" width="624"/><div>D4: Prompt Generation</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>提示语的生成是一项NLG任务，并使用标准的NLG模型来执行这项任务。</div><div><a href="evernote:///view/24256724/s35/b2c10cbe-4cdd-4d40-8287-93f6de37bd4d/b2c10cbe-4cdd-4d40-8287-93f6de37bd4d/" rev="en_rl_none">LM-BFF: Making Pre-trained Language Models Better Few-shot Learners</a>：T5</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/45E5BC79-F97C-4DDA-9EF2-9E93EAEC82EF.png" height="325" width="651"/><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains：</div><div>领域适应算法，训练T5为每个输入生成独特的Domain Related Features（DRFs；一组描述领域信息的关键词）。然后，这些DRFs可以与输入的内容连接起来，形成一个模板，并被下游任务进一步使用。</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/64907132-FA72-46BD-83B6-0412E545AFC1.png" height="772" width="990"/><div>D5: Prompt Scoring</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>Commonsense Knowledge Mining from Pretrained Models</div><div>评估了knowledge base completion任务，并使用LMs为输入（头-关系-尾三者）设计一个模板。他们首先手工制作了一组模板作为潜在的候选者，并将输入和回答的槽位填满，形成一个填充的prompt。然后，他们使用单向LM对这些填充了的prompt进行评分，选择LM概率最高的一个。这将导致为每个单独的输入定制模板。</div></div><h3>4.3.2 Continuous Prompts——embedding</h3><div>构建prompt的目的是让模型完成任务，prompt没有必要限制为人能理解的语言。</div><div>直接在模型的嵌入空间中进行提示，如此一来(1) 放宽模板词的嵌入是自然语言（如英语）词的嵌入的限制。(2)取消了模板由预训练的LM的参数决定的限制。相反，模板有自己的参数，可以根据下游任务的训练数据进行调整。</div><div>C1: Prefix Tuning</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/e4022f45-2476-4933-bbc6-d30d98567f51/e4022f45-2476-4933-bbc6-d30d98567f51/" rev="en_rl_none">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></div><div>在保持LM参数不变的情况下，将一连串连续的任务特定的向量拼接到到输入前（每一层）。</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/A9A64542-F11D-4537-98CE-1E1AF7F2B868.png" height="56" width="416"/><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/a86f9c28-5568-4965-a02c-c5aeed784323/a86f9c28-5568-4965-a02c-c5aeed784323/" rev="en_rl_none">The Power of Scale for Parameter-Efficient Prompt Tuning</a></div><div>在输入序列前加上special tokens，形成一个模板，并直接微调这些tokens的嵌入。</div></div><div>C2: Tuning Initialized with Discrete Prompts</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>Factual Probing Is [MASK]: Learning vs. Learning to Recall</div><div>首先使用离散的搜索方法（如AUTOPROMPT）定义一个模板，然后对embeddings进行微调以提高任务的准确性。认为用手动模板初始化可以为搜索过程提供一个更好的起点</div><div><br/></div><div><a href="evernote:///view/24256724/s35/ddcf4fa1-5388-4afb-85f1-aeee8cad4254/ddcf4fa1-5388-4afb-85f1-aeee8cad4254/" rev="en_rl_none">WARP: Word-level Adversarial ReProgramming</a></div><div>形状遵循手工的提示模板。使用Adversarial RePrograming给输入增加扰动，使得模型根据扰动输出指定的标签（<a href="evernote:///view/24256724/s35/50c3b427-aa45-4b81-852e-d8fa04772bb1/50c3b427-aa45-4b81-852e-d8fa04772bb1/" rev="en_rl_none"><u>Adversarial RePrograming</u></a>来自CV领域，目的是找到一种对抗扰动，对目标模型进行重新编程，以执行攻击者选择的任务。）</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/D2A2213B-6832-4CAE-B773-51DF9121D044.png" height="495" width="838"/><div>C3: Hard-Soft Prompt Hybrid Tuning</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/8193af23-5560-4a03-a841-ae043f660954/8193af23-5560-4a03-a841-ae043f660954/" rev="en_rl_none">P-tuning: GPT Understands, Too</a></div><div>在输入的embedding中插入可训练的变量来学习。用BiLSTM增强soft-prompt embedding的表示之间的互动。P-tuning还引入了在模板中使用与任务相关的anchor token（如关系提取中的 "capital"），以进一步改进。这些anchor token在训练中不被调整。</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/818739A2-5372-4D3A-B5C9-F41881427872.png" height="662" width="1916"/><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/cb9507b2-e144-4818-95bb-fbe75726e033/cb9507b2-e144-4818-95bb-fbe75726e033/" rev="en_rl_none">PTR: Prompt Tuning with Rules for Text Classification</a></div><div>提出基于规则的提示学习PTR，人为设计基本的子提示，并应用逻辑规则将子提示组成最终的特定任务提示。为了提高模板的表示能力，他们还插入了几个虚拟token，这些虚拟token的嵌入可以与预先训练好的LMs参数一起使用训练样本进行调整。</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/4DB97BDF-6C57-48D7-AEE5-B9A3B92A0B64.png" height="1674" width="2978"/><h1><span style="font-weight: bold;">5 Answer Engineering</span></h1><div>旨在寻找一个答案空间Z和标签Y的映射，从而形成一个有效的预测模型。</div><h2>5.1 Answer Shape</h2><div>答案形式按照生成文本的粒度可以划分为Tokens、Span、Sentence</div><div>答案形式的选择取决于任务，NLU任务通常使用Tokens、Span，NLG任务通常使用Sentence，也有multiple-choice question answering任务使用Sentence。</div><h2>5.2 Answer Space Design Methods</h2><div>答案空间和答案与标签的映射关系的设计。</div><h3>5.2.1 Manual Design</h3><div>Unconstrained Spaces：在许多情况下，答案空间Z是所有token的空间，固定长度的Span，或token序列。在这些情况下，最常见的是使用identity mapping将答案z直接映射到最终输出的y上</div><div>Constrained Spaces：输出空间受限，一般为标签空间受限，如文本分类、实体识别、选择性QA任务。在这些情况下，常见的做法有对每个标签人工给定一系列相关词，以此构建映射关系。</div><h3>5.2.2 Discrete Answer Search</h3><div>人工构造的映射是sub-optimal的。</div><div>Answer Paraphrasing：</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/88f01871-89f5-4633-be16-f2d215d3f982/88f01871-89f5-4633-be16-f2d215d3f982/" rev="en_rl_none">LPAQA: How Can We Know What Language Models Know?</a></div><div>使用回译法生成多个候选答案</div></div><div>Prune-then-Search：</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/bde186a5-8fe5-4c23-9d8f-92a43e512106/bde186a5-8fe5-4c23-9d8f-92a43e512106/" rev="en_rl_none">AUTOPROMPT: Eliciting Knowledge from Language Models with Automatically Generated Prompts</a></div><div>使用[Z]标记的表示作为输入，学习一个逻辑分类器。在搜索步骤中，他们选择使用第一步中学习的逻辑分类器获得最高概率分数的top-k个tokens。这些被选中的tokens将构成答案。</div><div><br/></div><div><a href="evernote:///view/24256724/s35/7e2b39f9-0eb5-4fc2-8d50-f54d712477e2/7e2b39f9-0eb5-4fc2-8d50-f54d712477e2/" rev="en_rl_none">KPT: Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification</a></div><div>借助外部知识扩展了verbalizer的标签词空间，提高覆盖度并减少偏见。</div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/252D825C-6C5E-4E55-BF9A-9707BD7DC2F7.png" height="867" width="1447"/><div>Label Decomposition：</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>Adaprompt: Adaptive prompt-based finetuning for relation</div><div>关系抽取任务，将关系词拆分为多个词，将多个词的预测概率累加作为标签预测概率</div></div><h3>5.2.3 Continuous Answer Search</h3><div>可以通过梯度下降进行优化的soft-answer tokens。</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/ddcf4fa1-5388-4afb-85f1-aeee8cad4254/ddcf4fa1-5388-4afb-85f1-aeee8cad4254/" rev="en_rl_none">WARP: Word-level Adversarial ReProgramming</a></div><div>为每个类标签分配一个虚拟标记，并优化每个标记的嵌入</div></div><h1>6 Multi-Prompt Learning</h1><div>为一个输入构建多个提示。</div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/4FEAB644-C2B1-4673-9154-8B4A8C132808.png" height="657" width="1064"/><h2>6.1 Prompt Ensembling</h2><div>Uniform averaging</div><div>Weighted averaging：权重可以根据prompt的性能指定或通过训练集优化</div><div>Majority voting</div><div>Knowledge distillation：使用知识蒸馏到一个模型中</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div><a href="evernote:///view/24256724/s35/a01f0b0c-ac14-4e78-a6a5-2dca0ff5dd50/a01f0b0c-ac14-4e78-a6a5-2dca0ff5dd50/" rev="en_rl_none">PET: Exploiting Cloze Questions for Few Shot Text Classification and Natural  Language Inference</a></div></div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/9D816BB0-C799-492C-A49C-92CA54CC7957.png" height="526" width="414"/><div>Prompt ensembling for text generation：使用多个模型进行生成，根据生成概率进行打分</div><h2>6.2 Prompt Augmentation/demonstration learning</h2><div>在prompt的基础上提供示例。难点在于示例的选择和排列的顺序。类似于基于抽取式的方法提升模型性能。</div><div>Sample Selection：LMBFF选择句子表示接近的示例；不同类别样本。</div><div>Sample Ordering：OrderEntropy提出基于能量的方法对不同排列进行打分；PERO提出寻找一个好的训练例子的排列组合作为增强的prompt，并在prompts之间学习一个分隔符以进一步提高性能。</div><h2>6.3 Prompt Composition</h2><div>对于一些组合性的任务，可以先将其拆分为不同的子任务，针对不同的子任务设计sub-prompts，再将这些sub-prompts的组合起来构成新的prompt。如KPT，关系抽取对实体属性有要求，可以先预测实体属性再进行关系分类，而且还能节省时间。</div><h2>6.4 Prompt Decomposition</h2><div>向NER任务，需要预测多个实体的类型，同时预测可能会超出需训练模型输入长度，因此需要为每一个实体单独进行预测。</div><div>当然也有像<a href="evernote:///view/24256724/s35/baec9da3-0c12-45b2-9d4d-0781d86f942e/baec9da3-0c12-45b2-9d4d-0781d86f942e/" rev="en_rl_none">EntLM: Template-free Prompt Tuning for Few-shot NER</a>直接进行NER预测。</div><h1>7 Training Strategies for Prompting Methods</h1><h2>7.1 Training Settings</h2><div>通常而言只利用参数固定的LM，不进行任何训练属于Zero-shot setting；</div><div>也有工作使用有标记数据进行训练，为full-data setting；</div><div>或少量数据few-shot setting，这个场景下prompt learning通常较为有效，因为它能让模型在少量样本的情况下，向正确的方向高效地训练。</div><div><a href="evernote:///view/24256724/s35/45f3d899-fbd0-4536-abed-790fd8cb90bd/45f3d899-fbd0-4536-abed-790fd8cb90bd/" rev="en_rl_none">True Few-Shot Learning with Language Models</a>指出现有的一些工作虽然没有使用有标注的训练数据训练模型，但是使用这些数据构造或验证了下游任务使用的prompts，对于下游任务来说不是True Zero-shot learning。</div><h2><span style="font-weight: bold;">7.2 Parameter Update Methods</span></h2><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/0BBA29C5-B42B-4B93-97ED-8E345B3D9236.png" height="297" width="845"/><div><br/></div><div><br/></div><h1>8 Applications</h1><p style="text-align:start;">使用prompting技术的相关工作：  </p><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/2432500C-F5E1-49C2-8CF1-CC069520AA8C.png" height="1536" width="1056"/><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/8B3CC4FD-A741-49E4-812D-B6F01D5ED5BF.png" height="1594" width="1054"/><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/FDE69989-4E9F-4E9F-A90A-97926B143B37.png" height="1968" width="1316"/><h1>9 Prompt-relevant Topics</h1><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/D7C52C73-6361-40DC-BDB3-89BF9F47CAF6.png" height="722" width="865"/><h1>10 Challenges</h1><h1>11 Meta Analysis</h1><p style="text-align:start;">相关工作的发表时间线：  </p><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/E48E54EE-79A8-43D9-AEA5-7E21A80A1539.png" height="1784" width="1182"/><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/29363D2C-741D-4D57-A6AD-4F99DAC41270.png" height="418" width="1192"/><hr/><p style="text-align:start;">引用到的Pre-trained Language Models：  </p><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/B0A4EC92-0C93-403F-A9C2-B5B7C5D635BF.png" height="1584" width="1208"/><div>模型参数量：</div><img src="%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0%20Prompt%20Learning.resources/5B63CD31-527C-4392-9F80-2AB7ADA5A532.png" height="262" width="621"/><div><br/></div><h1>参考文献：</h1><ol><li><div>Pre-train, Prompt, and Predict: A Systematic Survey of  Prompting Methods in Natural Language Processing</div></li><li><div><a href="evernote:///view/24256724/s35/5d12da7a-6e45-477b-861e-ef6ac48c803c/5d12da7a-6e45-477b-861e-ef6ac48c803c/" rev="en_rl_none">P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</a></div></li><li><div><a href="evernote:///view/24256724/s35/8193af23-5560-4a03-a841-ae043f660954/8193af23-5560-4a03-a841-ae043f660954/" rev="en_rl_none">P-tuning: GPT Understands, Too</a></div></li><li><div>The power of scale for parameter-efficient prompt tuning</div></li><li><div><a href="evernote:///view/24256724/s35/e4022f45-2476-4933-bbc6-d30d98567f51/e4022f45-2476-4933-bbc6-d30d98567f51/" rev="en_rl_none">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></div></li></ol><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>