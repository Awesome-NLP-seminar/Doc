{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb72968",
   "metadata": {},
   "source": [
    "# 模型参数初始化\n",
    "\n",
    "参数初始化的重要性  \n",
    "\n",
    "初始化思路\n",
    "\n",
    "初始化策略\n",
    "\n",
    "为什么Transformer 除$\\sqrt{d_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5459485",
   "metadata": {},
   "source": [
    "## 参数初始化的重要性 \n",
    "https://www.deeplearning.ai/ai-notes/initialization/\n",
    "\n",
    "https://towardsdatascience.com/what-is-weight-initialization-in-neural-nets-and-why-it-matters-ec45398f99fa\n",
    "\n",
    "参数设置过大或者过小都会导致模型不能训练或训练时间过长"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f0ac2",
   "metadata": {},
   "source": [
    "## 初始化思路\n",
    "思路： 输入数据和输出数据的模长保持不变\n",
    "\n",
    "对于正交矩阵W: \n",
    "\n",
    "$\\Vert Wx\\Vert^2 = x^\\top W^\\top Wx = x^\\top x =\\Vert x\\Vert^2$\n",
    "\n",
    "对于全连接层： $y = Wx + b$, 全零初始化b, 并将W初始化为正交矩阵。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aba271",
   "metadata": {},
   "source": [
    "### 怎样得到正交矩阵？\n",
    "推论1： 高维空间中的任意两个随机向量几乎都是垂直的。\n",
    "\n",
    "推论2: 从$\\mathcal{N}(0, 1/n)$中随机选取$n^2$个数，组成n*n的矩阵，这个矩阵近似为正交矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6158e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.23638913  0.15947432 -0.0455157  ... -0.08210088  0.0087467\n",
      "  -0.17826778]\n",
      " [ 0.15947432  1.12888214  0.01165964 ... -0.15408815  0.12484842\n",
      "   0.01831499]\n",
      " [-0.0455157   0.01165964  0.8616019  ...  0.06651855  0.00147615\n",
      "  -0.03701675]\n",
      " ...\n",
      " [-0.08210088 -0.15408815  0.06651855 ...  1.11691626 -0.18314423\n",
      "  -0.11051729]\n",
      " [ 0.0087467   0.12484842  0.00147615 ... -0.18314423  1.22016767\n",
      "  -0.01922771]\n",
      " [-0.17826778  0.01831499 -0.03701675 ... -0.11051729 -0.01922771\n",
      "   0.84414783]]\n",
      "MSE 0.01023289441320619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 100\n",
    "W = np.random.randn(n, n) / np.sqrt(n)\n",
    "X = np.dot(W.T, W)  # 矩阵乘以自身的转置\n",
    "print(X)  # 看看是否接近单位阵\n",
    "print('MSE', np.square(X - np.eye(n)).mean())  # 计算与单位阵的mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe46057",
   "metadata": {},
   "source": [
    "推论一：$x_i, y_i$从正态分布采样\n",
    "$$\\mathbb{E}[x^\\top y] = \\mathbb{E}[\\sum_i^n x_i y_i] = \\sum_i^n \\mathbb{E}[x_i y_i] = n\\mathbb{E}[x_i] \\mathbb{E}[y_i] = 0$$\n",
    "\n",
    "推论二： \n",
    "因为$\\mathbb{E}_{x\\sim \\mathcal{N}(0, 1)} [x^2] = var(\\mathcal{N}(0, 1)) = 1$\n",
    "\n",
    "所以，从$\\mathcal{N}(0, 1)$中采样的n维向量模长期望是$\\sqrt{n}$ ， 为了构造正交矩阵，从$\\mathcal{N}(0, 1/n) $中采样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac912985",
   "metadata": {},
   "source": [
    "### 怎么初始化？\n",
    "\n",
    "考虑全连接层 :$y = Wx + b, W\\in R^{m\\times n}$\n",
    "\n",
    "全零初始化b， 以随机正交矩阵初始化。\n",
    "\n",
    "当$m\\ge n$时， 从$\\mathcal{N}(0, 1/m)$中采样的矩阵，近似满足$W^\\top W = I$, \n",
    "\n",
    "若$m < n$, W不是行满秩矩阵，不存在$W^\\top W = I$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d640dd",
   "metadata": {},
   "source": [
    "## 初始化策略\n",
    "上文没有考虑激活函数，常用的初始化策略有\n",
    "\n",
    "### LeCun初始化\n",
    "$\\mathcal{N}(0, 1/m)$\n",
    "\n",
    "### He 初始化\n",
    "$\\mathcal{N}(0, 2/m)$\n",
    "\n",
    "针对激活函数为relu的情况， 有一半的输出被置0， 所以模长会减小为$1/\\sqrt{2}$倍\n",
    "\n",
    "### Xavier 初始化\n",
    "$\\mathcal{N} (0, 2/(m+ n))$\n",
    "\n",
    "对比： https://www.deeplearning.ai/ai-notes/initialization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e31a3",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    " \n",
    "$$\\mathrm{Attention} (Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$\n",
    "\n",
    "为什么除$\\sqrt{d_k}$?\n",
    "\n",
    "假设$q_i, k_i \\sim \\mathcal{N}(0, 1)$, \n",
    "\n",
    "$\\mathbb{E}[(q^\\top k)^2] = \\mathbb{E}[(\\sum_{i=1}^d q_i k_i)^2] = \\mathbb{E} [(\\sum_i q_i k_i)(\\sum_j q_j k_j)] = \\mathbb{E} [\\sum_{i, j}(q_i q_j)(k_i k_j)] = \\sum_{i,j} \\mathbb{E}[q_iq_j] \\mathbb{E} [k_i k_j] = d $\n",
    "\n",
    "大致可以认为，内积后的数值在$-3\\sqrt{d}$到$3\\sqrt{d}$之间， $d=64, \\sqrt{d}=8$当$3\\sqrt{d}$过大时，softmax的效果会类似arg max, 出现梯度消失的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac86ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25110f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a1309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e6bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a9b7702",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python xut_transformers",
   "language": "python",
   "name": "xut_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
