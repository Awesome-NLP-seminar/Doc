<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.22 (466988)"/><meta name="author" content="songdj"/><meta name="created" content="2022-05-19 14:18:44 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="updated" content="2022-05-23 14:22:40 +0000"/><meta name="content-class" content="yinxiang.superNote"/><title>【综述】Parameter-efficient Methods</title></head><body><div><br/></div><div><br/></div><div><br/></div><div>Must-read papers on parameter-efficient methods (Delta Tuning) for pre-trained models</div><a style="--en-type:bookmark;--en-hash:2690443985624967000;" href="https://github.com/thunlp/DeltaPapers"><var title="title" style="display:none;">GitHub - thunlp/DeltaPapers: Must-read Papers of Parameter Efficient Methods on Pre-trained Models (Delta Tuning).</var><var title="description" style="display:none;">Must-read Papers of Parameter Efficient Methods on Pre-trained Models (Delta Tuning). - GitHub - thunlp/DeltaPapers: Must-read Papers of Parameter Efficient Methods on Pre-trained Models (Delta Tun...</var><var title="icon" style="display:none;">data:image/png;base64,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</var><var title="thumbnail" style="display:none;">data:image/png;base64,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</var>https://github.com/thunlp/DeltaPapers</a><div><br/></div><div><br/></div><h1>1. 引言</h1><div>随着硬件设备的发展，深度学习逐渐取代基于统计的学习方法，并在近年有了巨大的发展。基于预训练-微调的范式被广泛使用。而随着模型容量逐渐增长，微调大模型所需要的资源往往无法获得，这引出了一个问题：我们真的需要微调模型的所有参数吗？</div><div>从ACL 2021, EMNLP 2021, NAACL 2021, ACL 2020, and EMNLP 2020 5个会议中随机抽取100篇文献，统计其使用预训练模型的大小。发现学术界仍然存在惰性，导致研究中很少使用大型模型，同时，部署和实验验证大型PLM的成本阻碍了NLP研究的发展。</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/AE89886A-2EAA-47F2-9CB6-D7B90F9CA90E.png" height="222" width="798"/><div>由此，参数高效的方法被提出。本文将这种方法称为delta-tuning，鉴于微调阶段调整的是模型的适应性参数（模型本身的或者额外增加的一小部分参数）。一些工作【Adapter-tuning; Prefix-tuning; prompt-tuning; BitFit; LoRA; Unified】已经表明仅通过微调一小部分的模型参数，也能在下游任务上取得很高的性能，甚至媲美微调的效果。而且这些工作也为进一步揭示大模型的工作原理提供思路。</div><h1>2. 预训练模型基础</h1><div>主流的PLM都使用Transformer架构，回顾Transformer架构，由堆叠的transformer block构成，每一个block包含多头注意力层和一个两层FFN，中间用Residual链接并加入了Batch Normalization：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/4A7CEB90-AED6-4215-9CAF-54DF69A329D0.png" height="1060" width="678"/><div>使用Transformer架构的PLM根据是否使用encoder和decoder主要可以分为三种：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/9EF47B66-1415-4693-A272-A9E2D973877A.png" height="500" width="1636"/><p>1.Masked Language Modeling系列包括BERT和RoBERTa等，仅包含encoder，预训练目标为MLM损失：</p><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/034BBEB4-16E0-452D-9B5F-1CD4F55B9A44.png" height="128" width="658"/><div>2.Auto-regressive Language Modeling系列包含GPT和GPT2，仅使用decoder，预训练目标为LM：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/703B635F-EF1C-425D-A27B-A1903AE67D08.png" height="146" width="700"/><div>3.Sequence to Sequence Modeling系列包含T5和BART，使用encoder-decoder，预训练目标为Seq2Seq MLM：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/BC32104D-976A-4C95-A038-CB4BACE55593.png" height="150" width="900"/><h1>3. Delta tuning</h1><div>根据对模型参数的不同操作可以将delta-tuning分为addition-based, specificationbased, and reparameterization-based：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/C47157DD-1984-4AC3-98F9-EEB6C51BDDA0.png" height="506" width="1640"/><div>不同delta-tuning方法的比较：F (FFN), H (Attention)</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/464792C3-167C-41C9-A624-401309C591E8.png" height="1398" width="1666"/><h2>3.1 Addition-based</h2><div>Addition-based方法根据delta参数的位置分两大类，Adapters-based tuning和Prompt-based tuning。</div><h3>3.1.1 Adapters-based Tuning</h3><div>基于适配器的方法提出将一小部分的神经模块插入到Transformer层之中，对于小模块的结构有很多选择。</div><hr/><div>(Houlsby et al., 2019)最早提出了一个简单的实现，成为很多工作的baseline。它提出在每一层的多头自注意力层和FFN层之后加入down-projection 和 up-projection操作，将特征降维经过非线性操作后再还原到原来的维度。每层增加的参数量为2 × ( 2dr (projection matrices) + d (residual connection) + r (bias term))。参数量仅为模型的0.5%∼8%。</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/F6302326-F924-41E8-AD5E-33431885B19E.png" height="68" width="398"/><hr/><div>Compacter (Mahabadi et al., 2021a)提出使用超复数乘法和参数共享的组合。超复数乘法将原始线性层参数化为两个小矩阵的Kronecker乘积之和。以down-projection为例：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/2F31D300-0C21-47E1-AE2D-7D0465DDEB9C.png" height="120" width="824"/><div>他们的方法将适配器层的参数数量减少到1/n而不损害性能，其中n是线性层的划分数量。它还表明，对线性层进行简单的<b>低秩分解</b>会有与适配器层相当的性能：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/57503EEE-8331-491E-9897-FA19730D3890.png" height="76" width="978"/><hr/><div>基于适配器的方法可以用于多任务场景(Stickland &amp; Murray, 2019; Mahabadi et al., 2021b)。</div><div>adapterFusion (Pfeiffer et al., 2021)首先预训练特定任务的适配器，然后结合预训练适配器的表征，利用跨任务知识，提高迁移学习的性能。</div><hr/><div>训练适配器比微调快60%，推理速度慢4-6%。将低层的适配器去掉可以进一步加速(Rücklé et al., 2021)。</div><div>有研究表明适配器有更强的鲁棒性，特别是在<b>少样本和跨语言场景</b>(He et al., 2021)。对对抗攻击更鲁棒(Han et al., 2021a)。</div><div>适配器可以视为对任务信息的 "封装"。AdapterHub(Pfeiffer et al., 2020a)提供了工具便于使用和部署不同的适配器。</div><h3>3.1.2 Prompt-based Tuning</h3><div>prompt-based learning通过在下游任务中使用模板来模拟预训练目标。(Gao et al., 2021; Hu et al., 2021b; Tan et al., 2021)(Scao &amp; Rush, 2021)(Liu et al., 2021a; Ding et al., 2021)。本文聚焦于prefix或prompt会被优化的prompt工作，不考虑模型和prompt同时优化的情况。</div><hr/><div>prefix-tuning (Li &amp; Liang, 2021)将可训练的连续标记（前缀）预置到每个Transformer层的input/hidden-states前。每层的prefix从一个新初始化的可训练参数矩阵中获得，冻结模型其他参数。认为此方法可以广泛用于自回归和Seq2Seq方法。</div><div>P-tuning V2 (Liu et al. 2021b)认为这种策略可以用于NLU任务。</div><hr/><div>相比于在每一层加入相同的prefix，prompt tuning (Lester et al., 2021)提出直接在input中加入soft prompts。随着模型容量的增加，该方法的性能和微调更加接近。</div><div>这种方法对soft prompts的长度和初始化较为敏感。PPT(Gu et al., 2021)将soft prompt加入到预训练阶段来获得一个好的初始化点。</div><div>（Vu等人，2021；Su等人，2021）发现prompt tuning有跨任务的可迁移性，这表明适当的初始化可能对下游任务大有裨益。</div><hr/><div>prompt-based方法的缺陷在于难以优化soft prompt，特别是在数据量小，模型较小时。而且收敛速度显著慢于微调和其他delta方法。</div><h2>3.2 Specification-based Methods</h2><div>这类方法只调模型参数中的少量部分。这部分参数的选择可以通过启发式方法或训练获得。</div><h3>3.2.1 Heuristic Specification</h3><div>Lee et al. (2019)只调Bert Roberta最后一层的1/4可以达到90%的微调性能。</div><hr/><div>BitFit (Zaken et al., 2021)仅调bias可以达到95%的性能。且在小模型上随机选择一定的参数做训练，也可以在GLUE上得到合格的结果。</div><h3>3.2.2 Learn the Specification</h3><div>diff pruning (Guo et al., 2021)将微调后的模型参数Θ′重新参数化为预训练参数Θ和差分向量ΔΘ的总和，即Θ′=Θ+ΔΘ，其中|Θ|=|Θ′|。因此，关键问题是鼓励差分向量尽可能地稀疏，这项工作通过对L0-norm惩罚的可微调近似来规范向量，以实现稀疏性的目标。实际上，由于要优化的新参数是在学习阶段引入的，因此diff修剪比全参数微调占用更多的GPU内存，这可能会在大型PLM的应用中建立障碍。</div><hr/><div>掩码方法（Zhao等人，2020）为PLM学习选择性掩码，只更新特定任务的关键权重。为了学习这样一组掩码，引入了一个与模型权重相关的二进制矩阵，其中每个值由一个阈值函数生成。在反向传播过程中，该矩阵由一个噪声估计器更新。</div><h2>3.3 Reparameterization-based Methods</h2><div>将优化过程中的适应性参数转化为参数高效的形式。</div><div>这一类方法的动机是假设PLM对大多数下游任务的适应本身是low-rank的，因此可以用参数高效的方式完成。</div><div>三项工作的动机差异：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/42B7C39C-0DB7-412F-8AA9-1D67C1C9BE95.png" height="610" width="1704"/><h3>3.3.1 Intrinsic Dimensions of PLM Adaptation</h3><div>Aghajanyan等人（2021）通过经验表明，预训练模型的全参数微调过程可以被重新参数化为低维子空间内的优化，即微调具有较低的<b>内在维度</b>（Li等人，2018），衡量达到满意性能所需的最小参数数。在实验中，他们发现一个相对低维（如数千）的重新参数化可以达到85%以上的微调性能。在这个意义上，PLMs可以作为一般的压缩框架，将优化的复杂性从高维压缩到低维。他们还证明，较大的PLM通常具有较小的内在维度，而预训练的过程隐含着降低PLM的内在维度。从这些观察中得到的启发，提出了基于重新参数化的delta-tuning方法，用<span style="background-color: #fff199;">低维代理参数</span>重新参数化（部分）原始模型参数，只优化代理参数，从而减少计算和内存成本。</div><h3>3.3.2 Intrinsic Rank of Weight Differences</h3><div>受启发于上，LoRA (Hu et al., 2021a)假设训练过程中模型参数的变化有low intrinsic rank。他们提出优化low-rank分解，以<span style="background-color: #FFF199;">改变自注意模块中的原始权重矩阵</span>。在推理阶段用两个分解矩阵的乘积加入自注意力原始矩阵。达到了微调同样的效果。</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/EDDBD232-9C99-4E56-90DE-CE028173539E.png" height="598" width="548"/><h3>3.3.3 Intrinsic Space of Multiple Adaptations</h3><div>此外，Qin等人（2021b）提出了一个更有力的假设，即对多个任务的适应可以重新参数化为<span style="background-color: #fff199;">同一</span>低维内在子空间内的优化。他们没有求助于随机子空间（Aghajanyan等人，2021），而是试图找到各种NLP任务<span style="background-color: #fff199;">共享的共同子空间</span>，通过将<span style="background-color: #fff199;">多个NLP任务的训练好的soft prompts分解</span>到同一个低维非线性子空间来实现，然后只通过调整子空间中的参数来学习使PLM适应未见的任务或数据。实验表明，在用100个随机任务找到的250维子空间中，通过只调整250个自由参数，可以分别为100个看过的任务（使用不同的训练数据）和20个未看过的任务恢复97%和83%的完全prompt tuning性能。这为他们的通用重参数化假说提供了强有力的证据，并可能启发未来的工作。此外，Qin等人（2021b）还表明，低维重新参数化可以显著提高prompt tuning的稳定性。他们的方法也可以作为分析各种NLP任务的相似性和差异性的工具来加以利用。</div><h1>4. Theoretical Perspectives of Delta Tuning</h1><div>这些方法本质上是在做同一件事吗？我们对delta tuning背后的理论原则感兴趣。一个预先训练好的语言模型通常可以很容易地适应几乎所有的下游任务，而只需要很小的成本（与预先训练相比），这种现象导致了值得深入探讨的理论问题。在这一节中，我们提出了两个框架，从优化（§4.1：优化）和最优控制（§4.2：最优控制）的角度介绍delta调整的理论见解。</div><h2>4.1 Optimization Perspective for Delta Tuning</h2><div>初始情况下，delta-tuning的目标函数 和 原始语言模型的目标函数值相等：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/EC9DE5B2-21FD-47A1-A8DD-0D98A56CD09E.png" height="80" width="1516"/><div>有以下关系，delta-tuning的目标函数同时优化<b>原模型参数和delta参数</b>是最优的：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/58531CAC-C43A-4697-89FA-16EB80E00B2A.png" height="86" width="1510"/><div>当</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/AF057D8A-DA16-48D9-86D5-A3B1DDFBF75F.png" height="46" width="812"/><div>且F是二阶Lipschitz连续可分，在(θ+, δ0) and (θ0, δ+)的局部区域，有如下误差边界：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/F1D5DBD2-BFF1-4D54-8603-A4850DA55AFE.png" height="50" width="1502"/><div>然而，为了保证delta-tuning的有效性，必须利用问题结构来设计～F。其直觉是要利用问题的内在低维度。基本上，有两种方法在实践中是有用的：</div><div>- 解决方案在一个较低维度的子空间中被更新； </div><div>- 目标函数（含约束）在某个较小的函数子空间中被逼近。</div><div>对于深度学习的应用，由于过度参数化，目标函数的优化往往有很多局部最小化。因此，当起点接近局部最小化器时，这些方法通常工作良好，其中只有一些搜索方向是重要的，或者目标函数可以在信任区域被一些更简单的函数很好地近似。此外，小维度的优化可以带来更有效和更稳定的训练过程。</div><h3>4.1.1 Low dimensional representation in solution space</h3><div>由于观察到θ的优化轨迹近似于流形（Aghajanyan等人，2021），我们可以将隐藏的流形嵌入到δ的低维空间，即θ=ψ(δ)+\sigma，其中\sigma是取决于θ0、θ+的误差项。那么：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/9CAC3492-0E20-44A3-B450-9439633917D9.png" height="60" width="1516"/><div>如果\sigma=0，delta-tuning找到了原始语言模型微调的精确解。否则，最终的差异取决于近似误差、目标函数的条件数和训练过程的稳定性。设</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/6B1182AA-B059-4E31-9586-9336387DE255.png" height="38" width="670"/><div>。假设F和F◦ψ是Lipschitz连续的，Lipschitz常数分别为L1和L2。那么，我们有如下的delta-tuning对原始语言模型的全参数微调的近似误差约束：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/FA935513-E8AC-4C91-9EF7-4CB5EDF09A2B.png" height="112" width="1510"/><div>误差\sigma是由低维表示ψ的近似值控制的。由于F(ψ(δ))的最小化可以看作是F(θ)的扰动目标函数的最小化，所以只要F的条件好，优化算法稳定，则||δ′-δ+||_2是有界的。另外，如果δ′和δ+较小，约束（17）仍然可以导致F(ψ(δ+))的良好质量。</div><div>一些delta-tuning方法从这种方法中受益。在LoRA（Hu等人，2021a）中，权重矩阵W∈Rd×n被构造为W≈W0+AB，其中W0是δ0的对应部分，A∈Rd×r，B∈Rr×n是通过训练过程学习的秩-r的低秩矩阵。数值结果验证了低秩近似的假设（Hu等人，2021a）。在BitFit（Zaken等人，2021）或diff pruning（Guo等人，2021）中，δ的一些坐标在训练过程中被选中进行优化。因此，近似值为θ=θ0+V y，其中V的列由从单位矩阵中选择的列组成，y是待学习的低维向量。我们还可以对θ进行一些适当的变换，使F更容易被优化。例如，选择一个变换矩阵S，让Sθ=Sθ0+V y。由此产生的delta-tuning方法可以被看作是一个重新参数化，然后再进行diff pruning。</div><h3>4.1.2 Low dimensional representation in functional space</h3><div>另一种方法是直接设计一个与最终的F(θ+)相匹配的近似函数，也就是说，我们寻求找到ˆF(δ)，使得：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/756979DB-13D5-4418-BC23-82A4D3A5A635.png" height="58" width="1512"/><div>其中是近似误差。通过这种方式，我们认识到</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/82458FC1-6265-47AD-8E19-9DBC5E5F0879.png" height="52" width="556"/><div>。ˆF的构建可以用增量网络（Houlsby等人，2019）或增强的特征空间（Lester等人，2021）来描述。由于我们对语言模型的最终性能更感兴趣，而不是模型参数，所以直接对函数F(θ)进行建模是很有希望的，它近似限制在函数空间的一个小流形中，我们放弃了从模型参数中估计误差（17）的需要。</div><div>ˆF的构造是一门艺术，在实践中也有不同。最简单的策略是冻结网络的某些部分，如BitFit（Zaken等人，2021）。考虑更复杂的构造，可以提高近似度。由于函数的作用是由数据流表征的，一个自然的想法是在原始神经网络的数据路径中注入低秩表示，由此产生的新语言模型是一个像Adapter（Houlsby等人，2019）一样的增量网络，如（10）所示。近似误差（18）是由增量网络的表示能力决定的。由于多层前馈网络的普遍近似特性（Leshno等人，1993），近似的质量得到了保证。值得注意的是，在计算机视觉领域也提出了类似的架构（Rebuffi等人，2017；Ye等人，2020）。</div><div>通过利用Transformer的自回归结构，可以构思一些更专门的函数近似。请注意，目标函数一般由输入和模型参数决定，即L((X, Y ); θ)。原则上，我们可以冻结模型参数θ，并使X和Y成为变量。在某些情况下，交换(X, Y )和θ的位置可能很方便，以获得一个更容易解决的优化问题。由于θ是预训练的语言模型，处理起来很不方便，所以用一些可训练的～X来代替X是有意义的，因为在语言任务中，X的特征空间，即range(X)，一般被限制在几千维。这个想法在提示调谐中得到了利用（Lester等人，2021年），在提示调谐中，一系列的提示标记P被预置到输入的X中，提示P不以θ为参数，相反，它有单独的可训练参数θP。通过这种方式，特征空间被扩大了，但对于训练来说仍然是可行的。由于Transformer的自回归特性，近似函数可以作为待优化的原始函数F的良好替代物，引导语言模型专注于特定的任务。前缀调整（Li &amp; Liang, 2021）进一步使中间层的一些激活可被训练，从而导致更准确的功能近似，或者换句话说，扩大了修改后语言模型的表示能力。关于性能，由于提示调谐是一种降维方法，用较少的参数建立概率分布模型，其效果与模型大小和数据大小密切相关。随着模型规模和数据规模的增大，提示调谐容易取得更好的性能，这与降维理论是一致的（Wright &amp; Ma, 2021）。此外，对于高维问题，可以有更多的自由来选择函数近似的子空间，Su等人（2021）和我们在§5.3的实验结果。SCALE也验证了这个直觉。 </div><h3>4.1.3 The unified view of the approximations in solution space and functional space</h3><div>一般来说，由于对偶性关系，解空间和函数空间中的表征往往导致近似～F的相似构造。事实上，(He et al., 2022)通过分析修改后的语言模型中的数据流，提出了Adapter(Houlsby et al., 2019)、prefixing tuning(Li &amp; Liang, 2021)和LoRA(Hu et al., 2021a)的统一观点。指出这些delta-tuning方法都是构建原始数据流的低维修改，即h ← h + ∆h，其中∆h由一些低维的参数组成。这种观点可以被认为是从函数空间的角度来理解不同的delta-tuning方法。一些关于设计函数近似方法的有用的经验结果也可以在（He等人，2022）中找到。</div><div>我们的讨论表明，<span style="background-color: #FFF199;">所有这些delta-tuning方法的性能都依赖于低维假设</span>。事实上，甚至可以发现各种任务之间可能存在一些共同的子空间（Qin等人，2021b），Su等人（2021）和我们在§5.4中的实验结果。转移性也显示了delta-tuning在不同任务中的转移性。由于delta-tuning方法的实际性能不可避免地与问题有关，因此，利用手头任务中更多的特定结构或建立一些混合算法，使其与原始语言模型的完全微调更有竞争力，是很有希望的。</div><h2>4.2 Optimal Control Perspective for Delta Tuning</h2><div>Yang和Liu（2022）提议从最优控制的角度解释prefix-tuning。在这一节中，我们将最优控制的观点推广到不同的delta-tuning情景中。</div><h3>4.2.1 Relationship Between Optimal Control And Deep Learning</h3><div>我们首先从最优控制的角度来解释深度学习。根据Li等人（2017）的第4节，我们在下文中回顾了这些定理，并直接遵循他们的符号。</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/68DC752A-740E-4B80-A27D-73AF6FCDF100.png" height="692" width="1520"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/48FB8A7F-0173-4100-9EDD-4AE0AB2B06BC.png" height="532" width="1520"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/9E4B4F0D-04A3-45C8-A5D4-6AFD3B72ED5C.png" height="164" width="1512"/><h3>4.2.2 Tuned Delta’s As Optimal Controllers</h3><div>我们考虑用预训练的<b>自回归LM（如GPT-2）</b>进行文本分类的delta-tuning。通过将内容作为输入句子的框架，模型在最后一步产生预测的标签。为了简单起见，我们把标签预测的位置表示为o。在位置o，模型被输入了一个特殊的标记[ANS]，并被期望产生预测。</div><div>θ为L层PLM的参数。我们使用训练集D_{tr}来优化各层的delta参数。{δ(0), . . . , δ(L-1)}。第j层在第i步的中间激活被表示为h^{(j)}_i。delta-tuning的优化问题被表述为：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/5FF40404-37CC-402B-B272-A7B578F8768C.png" height="220" width="1512"/><div>其中，S为softmax评分函数，R为delta参数的正则器，z_i为输入的第i个标记，y为标签。函数G定义了在delta的干预下，LM中改变的前向传播。具体来说，可学习的δ^(j)激活了θ的固定参数，这样第j层的表征h^{(j)}_o就可以被适当地转换为G^(j)_θ( h^(j)_o, δ^(j) )。因此，两个连续层之间的表征转换由函数G和Transformer中的剩余连接来描述。</div><div>我们接着表明，问题（27）统一了具有不同G实例的各种delta-tuning方案。</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/455EFE5F-7F91-4556-9A15-93E6314AF805.png" height="766" width="1520"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/556D494B-0802-43AB-BC3A-2AA75B9612F1.png" height="718" width="1522"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/E0429B75-7D98-4910-A6A0-8E720A36AEE4.png" height="374" width="1526"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/76D0137E-04D3-471D-81DF-24AA7F8A17F0.png" height="202" width="1510"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/0A577D23-F907-4B70-A4F3-A47FE567647D.png" height="144" width="1508"/><div>我们列举了问题（27）中不同delta-tuning方法的函数G的表述。根据定理4.1，问题（27）中的S和R可以被看作是终端和运行损失，delta参数是控制变量。这意味着（27）可以被表述为一个<span style="background-color: #FFF199;">离散时间控制问题</span>。有了定理4.2和4.3，优化delta的前向和后向传播等同于Pontryagin’s Maximum Principle（Kopp, 1962）中的co-state process的计算。总而言之，delta-tuning可以被看作是为特定的下游任务寻求PLM的最佳控制。</div><div>我们的分析揭示了从控制理论中得到启发而设计出的新的delta-tuning方法。在设计稳健模型时，人们可以参考控制理论（Zhang等人，2019a）。例如，Yang和Liu（2022）提出了robust prefix-tuning，在推理过程中调整一个额外的robust prefix，以引导LM走向正确的预测。test-time activation rectification的想法可以被视为闭环反馈控制（Chen等人，2021）。我们还表明，Delta对PLM的干预等同于控制器的设计。通过应用控制器设计的理论（Boyd &amp; Barratt, 1991; Ang et al., 2005），我们期望提出更多具有理论保证的delta方法。所设计的delta结构原则上是可以解释的，同时充分地利用了PLM的力量。</div><h1>5. Comparisons and Experimental Discoveries</h1><div>性能、收敛性和效率分析</div><div>三种代表性的delta调谐方法的可组合性。手动模板对delta调谐方法的影响；</div><div>研究了缩放法SCALE</div><div>研究delta调谐方法在不同下游任务中的可转移性</div><h2>5.1 Performance, Convergence and Efficiency</h2><div>vanilla fine-tuning (FT), prompt tuning (PT), prefix-tuning (PF), LoRA (LR) and adapter (AP).</div><div>randomly select over 100 representative tasks</div><div>T5-BASE/T5-LARGE(PT)</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/1E49C817-CF8A-4F75-97D9-3FA8B1B44808.png" height="1586" width="1648"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/8CB4FE04-77E1-483F-B481-CA13C9DA0026.png" height="1864" width="1228"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/8FE97158-177A-4CB0-B974-3F89B0617531.png" height="688" width="1274"/><div><span style="background-color: #FFF199;"><b>FT &gt; LR &gt; AP &gt; PF &gt; PT</b></span></div><div><br/></div><div>收敛步数：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/3F8CBD87-C9E6-4401-B36E-1836D83376A2.png" height="1884" width="1572"/><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/DC47FF01-E89A-4808-881B-21A48EAAA0EB.png" height="1828" width="1550"/><div>内存消耗：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/4269A4D8-E06E-4138-843D-AD3C90F15A31.png" height="576" width="1990"/><div>模板：</div><img src="%E3%80%90%E7%BB%BC%E8%BF%B0%E3%80%91Parameter-efficient%20Methods.resources/8955EECA-96AC-4881-A859-4A5B9BB0262A.png" height="464" width="1518"/><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>